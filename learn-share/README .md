大数据平台架构的设计包括整体框架设计和整体技术架构设计。

**1、大数据平台整体架构**

大数据平台整体架构可分为七大部分：目录管理、数据集成、数据资产管理、数据治理、数据开发、数据分析、数据共享及数据安全。

![img](D:\UserData\Desktop\md\picture\v2-1ff665529e12b2345e7a209c6eb8fab6_1440w.jpg)

- 目录管理

通过盘点和梳理业务数据，编制、发布数据目录，规划和指导数据的接入、管理、治理、开发、共享等。

- 数据集成

为大数据平台提供基础支撑性服务，提供多种数据接入工具，实现结构化和非结构化的数据的汇聚接入，并支持数据的预处理，为大数据平台提供原始数据支撑。

- 数据资产管理

通过管理数据标准、元数据、数据资源等，提高数据资产的价值。

- 数据治理

规范数据的生成以及使用，发现并持续改善数据质量。

- 数据开发

提供大数据开发、分析、挖掘等功能。非专业的业务人员也可以利用图形化的IDE进行数据分析。

- 数据分析

提供从基本数据查询统计、数据交叉汇总、自由钻取分析、多维数据分析等多层次的数据分析功能。

- 数据共享

实现不同部门、不同格式数据的共享交换，以及异构系统之间、新老系统之间的信息的透明交换。

- 数据安全

提升一系列安全工具，包括数据加密、数据脱敏、数据备份、日志审计等。

**2、大数据平台技术架构**

大数据平台技术架构从下往上依次为数据源层、数据获取层、数据存储层、数据处理层、数据应用层。

![img](D:\UserData\Desktop\md\picture\v2-36818765d5c4a4056a17ff3f4b05b252_1440w.jpg)

- 数据源层

非结构化数据：包括图片、声音、视频等，这类数据通常无法直接知道它的内容，数据库通常将它保存在一个BLOB字段中。一般的做法是，建立一个包含三个字段的表（编号 number、内容描述 varchar(1024)、内容 blob）。引用通过编号，检索通过内容描述。

半结构化数据：半结构化数据具有一定的结构性，但是结构变化很大。因为我们要了解数据的细节所以不能将数据简单的组织成一个文件按照非结构化数据处理，由于结构变化很大也不能够简单的建立一个表和他对应。其存储方式有两种：一种是化解为结构化数据，另一种是用XML格式来组织并保存到CLOB字段中。

- 数据获取层

数据获取层的主要作用是实现多源异构数据的采集、聚合、传输及预处理，集成多种数据采集工具。

Sqoop(发音：skup)是一款开源工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据传递。它可以将一个关系型数据库（MySQL ,Oracle ,Postgres等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

Flume(发音：fluːm)是一个分布式的海量日志采集、聚合和传输系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。

消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过写和检索出入列队的针对应用程序的数据（消息）来通信，而无需专用连接来链接它们。消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信。

Kettle（发音：ketl）是一款开源ETL工具，可以跨平台上运行，绿色无需安装，数据抽取高效稳定。中文名称叫水壶，该项目的主程序员MATT 希望把各种数据放到一个壶里，然后以一种指定的格式流出。

kettle四大家族：

Chef（中文：厨师）：工作（job），设计工具 (GUI方式)；

Kitchen（中文：厨房）：工作(job)执行器 (命令行方式)；

Spoon（中文：勺子）：转换(transform)，设计工具 (GUI方式)

Pan（中文：平底锅）：转换(transform)执行器 (命令行方式)

- 数据存储层

关系数据库：Mpp（大规模并行处理）技术是基于关系数据库的成熟技术，伴随着分布式与并行数据库技术的发展而来。

非关系数据库：NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”。用以解决大规模数据集合多重数据种类问题。分为四大类：键值(Key-Value)存储数据库（如Redis），列存储数据库（如HBase），文档型数据库（SequoiaDB），图形(Graph)数据库（如Neo4J）。

分布式文件存储：HDFS是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它具有高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征，为海量数据提供了不怕故障的存储，为超大数据集（Large Data Set）的应用处理带来了很多便利。FastDFS是一个开源的轻量级分布式文件系统。功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。

全文索引：Solr是以Lucene搜索库为核心，提供全文索引和搜索的开源工具，提供REST的HTTP/XML和JSON的API。ES（ElasticSearch）是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。

- 数据处理层

离线数据处理：大数据离线处理一般使用 Hdfs或MPP 存储数据，使用MapReduce、Spark做批量计算，计算完成的数据如需数据仓库的存储，直接存入 Hive , 然后从Hive 进行展现。

实时数据处理：是指计算机对现场数据在其发生的实际时间内进行收集和处理的过程。



**如何理解数据湖概念？**

Pentaho 的首席技术官 James Dixon 对“数据湖”进行了介绍。之所以将其称为湖，是因为这种数据库可以在自然状态下存储大量数据，就像一片未经过滤或包装的水体。数据从多种来源流入湖中，然后以原始格式存储。

**数据湖和数据仓库的差别是什么？**

数据仓库可提供可报告的结构化数据模型。这是数据湖与数据仓库的最大区别。数据湖存储的是非结构化的原始数据，并未定义具体用途。

数据在存入数据仓库前，需要进行处理，决定哪些数据将会或不会存入数据仓库，这被称为“写时模式”。

在存入数据仓库前，数据的重新定义过程既耗时又艰难，有时需要花费数月甚至数年时间，导致无法及时收集数据。利用数据湖，可以即时开始收集数据，并确定其将来的用途。

鉴于其结构特点，商业分析员和提前知道自己需要用哪些数据完成定期报告的商业用户通常会使用数据仓库。而数据湖则多用于数据科学家和分析师，因为他们需要用数据进行研究，并且在使用前，数据需要经过更加高级的过滤和分析。

**数据湖的数据管理方式？**

数据湖内数据通常为各类数据的单一存储，包括源系统数据的原始副本，以及用于报告、可视化、分析和机器学习等任务的转换数据。数据湖可以包括来自关系数据库（行和列）的结构化数据，半结构化数据（CSV，日志，XML，JSON），非结构化数据（电子邮件，文档，PDF）和二进制数据（图像，音频，视频），因此数据湖的采集方式不一而足，需根据实际情况定制化开发，最终实现数据资源的整合，但是作为单一化存储的数据管理，采集的重点为采集后的数据资产目录信息生成，能够生成统一的元数据信息，可对数据湖进行监管和持续维护，保证数据的时刻可用和可访问，如果资产目录维护不当，采集汇聚而来的数据资源将毫无价值，无人访问、难以操作、无法检索，最终形成数据沼泽。